[[sec:khr-max-num-work-groups]]
= sycl_khr_max_num_work_groups

This extension allows developers to query iteration bounds in each dimension for a ND-range or basic range kernel.
The implementation ensures the execution of the ND-range kernel if its global size is less than of equal to `max_num_work_groups_nd_range<N>` in each dimension. This condition applies to basic range kernels with `max_num_work_groups_range<N>`.


[[sec:khr-max-num-work-groups-dependencies]]
== Dependencies

This extension does not depend on other extensions.

[[sec:khr-max-num-work-groups-feature-test]]
== Feature test macro
An implementation supporting this extension must predefine the `SYCL_KHR_MAX_WORK_GROUP_QUERY` macro to one of the values defined in the table below.

[%header,cols="1,5"]
|===
|Value
|Description

|1
|Initial version of this extension.
|===

== New device descriptors

[options="header"]
[cols="1,1,2", options="header"]
|===
| Device descriptors                                     | Return type | Description

| `khr::info::device::max_num_work_groups_nd_range<N>`
| `id<N>`
| Returns the maximum number of work-groups that can be submitted in each dimension of the `globalSize` of an `nd_range<N>`. The minimum value is `(1, 1, 1)` if the device is not `info::device_type::custom`.


| `khr::info::device::max_num_work_groups_range<N>`
| `id<N>`
| Returns the maximum number of work-groups that can be submitted in each dimension of a `range<N>` for a basic kernel. The minimum value is `(1, 1, 1)` if the device is not `info::device_type::custom`.
|===

=== Note
- N can take the value 1, 2 or 3
// - nd_range allow barrier, and other scemantic who may impact the maximun size of allocation, hence we split the querry between the range and nd_range?

[[sec:khr-max-num-work-groups-example]]
== Example

The example below demonstrates the use of this extension for an `nd_range` loop, the same code can be applied to a basic range by using the `max_num_work_group_range` device descriptor.

[source,cpp]
----

#include <iostream>
#include <sycl/sycl.hpp>

int
main(int argc, char *argv[]) {
    size_t dim1 = std::stoi(argv[1]);
    size_t dim2 = std::stoi(argv[2]);
    size_t dim3 = std::stoi(argv[3]);
    sycl::range<3> globalSize(dim1, dim2, dim3);
    sycl::range<3> localSize(1, 1, 1);

    sycl::queue queue;
    sycl::device device = queue.get_device();
    std::cout << "Running on " << device.get_info<sycl::info::device::name>()
              << "\n";

    sycl::id<3> nd_limit =
        gpu.get_info<sycl::khr::info::device::max_num_work_group_nd_range<3>>();
    std::cout << "Max number groups for ND-Range: x_max: " << nd_limit[2]
              << " y_max: " << nd_limit[1] << " z_max: " << nd_limit[0]
              << std::endl;

    // Should aways be satisfied at kernel submission
    // user's responsibility to check
    assert(globalSize[2] <= nd_limit[2]
        && globalSize[1] <= nd_limit[1]
        && globalSize[0] <= nd_limit[0]);

    // If the assertion if satisfied, the implementation guarantees
    // the execution of the kernel
    queue.parallel_for(
        sycl::nd_range{globalSize, localSize},
        [=](sycl::id<3> idx) { /*Kernel*/ }).wait();

    return 0;
}

----

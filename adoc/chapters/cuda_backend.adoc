// %%%%%%%%%%%%%%%%%%%%%%%%%%%% begin cuda_backend %%%%%%%%%%%%%%%%%%%%%%%%%%%%

[appendix]
[[chapter:cuda-backend]]
= CUDA backend specification

This chapter describes how the SYCL general programming model is mapped on top
of CUDA, and how the SYCL generic interoperability interface must be
implemented by vendors providing SYCL for CUDA implementations to ensure SYCL
applications written for the CUDA backend are interoperable.

The CUDA backend is enabled using the `sycl::backend::cuda` value of `enum
class backend`. That means that when the CUDA backend is active, the value of
`sycl::is_backend_active<sycl::backend::cuda>::value` will be `true`, and the
preprocessor macro `SYCL_BACKEND_CUDA` will be defined.

The CUDA backend requires an installation of CUDA SDK as well as one or more
CUDA devices available in the system.
[[sec:cuda:introduction]]
== Introduction

[[sec:cuda:mapping_of_sycl_programming_model]]
== Mapping of SYCL programming model

This section gives a general overview of how the SYCL programming model maps to
CUDA. These two programming models are pretty similar in essence however they do
have a few differences in terminology and architecture.

[[sub:cuda:platform_model]]
=== Platform Model

A SYCL device maps to a single CUDA device.  As CUDA does not split into
separate platforms there is no 'platform' concept in CUDA corresponding to the
SYCL platform. Instead, a SYCL platform maps to a collection of CUDA devices
represented by `std::vector<CUdevice>`.

A SYCL <<context>> simply maps to one, or multiple CUDA contexts. Indeed while
a CUDA context is tied to a single device, this is not the case for a SYCL
<<context>> and the CUDA backend implementation may use multiple CUDA contexts
to emulate a SYCL <<context>> containing multiple devices. Additionally, while
SYCL contexts are simple objects passed around either implicitly or explicitly,
CUDA contexts require to be activated on the current thread to be used by other
CUDA entry points. Therefore any use of the SYCL APIs with a CUDA backend may
modify the current active context on the thread, and no guarantee is provided
that any existing active CUDA context would be restored by SYCL.

A SYCL <<queue>> simply maps to one or multiple CUDA streams. Indeed while a
CUDA stream is in-order, a SYCL <<queue>> isn't, so a CUDA backend implementation
may use multiple CUDA streams to implement an out of order SYCL <<queue>>.

[[sub:cuda:memory_model]]
=== Memory model

==== Accessing memory on a different GPU

Devices belonging to the same context must be able to access (directly or indirectly) each other's global memory. This is done in one of the following ways:

- Device directly accesses memory on another device (peer-to-peer memory access).
- CUDA-runtime-managed memory is used. CUDA runtime copies the data from one device to another.
- Peer copy (one of [code]#CuMemcpyPeerAsync# or [code]#CuMemcpy3DPeerAsync#) is used to directly copy the data from one device to another.
- The data is copied from one device to the host, and then from host to another device.

==== Shared USM memory advices

Values for the `advice` parameter of `sycl::queue::mem_advise` and `sycl::handler::mem_advice` and their mapping to CUDA equivalent are defined in table <<table.cuda.memmodel.advices>>.

[[table.cuda.memmodel.advices]]
.Valid shared USM advices and their equivalents in CUDA
[width="100%",options="header",cols="40%,30%,30%"]
|====
| SYCL shared USM advice | CUDA managed memory advice | processor, the advice is set for
| CUDA_MEM_ADVISE_SET_READ_MOSTLY | cudaMemAdviseSetReadMostly | device associated with the queue/handler
| CUDA_MEM_ADVISE_UNSET_READ_MOSTLY | cudaMemAdviceUnsetReadMostly | device associated with the queue/handler
| CUDA_MEM_ADVISE_SET_PREFERRED_LOCATION | cudaMemAdviseSetPreferredLocation | device associated with the queue/handler
| CUDA_MEM_ADVISE_UNSET_PREFERRED_LOCATION | cudaMemAdviseUnsetPreferredLocation | device associated with the queue/handler
| CUDA_MEM_ADVISE_SET_ACCESSED_BY | cudaMemAdviseSetAccessedBy | device associated with the queue/handler
| CUDA_MEM_ADVISE_UNSET_ACCESSED_BY | cudaMemAdviseUnsetAccessedBy | device associated with the queue/handler
| CUDA_MEM_ADVISE_SET_PREFERRED_LOCATION_HOST | cudaMemAdviseSetPreferredLocation | host
| CUDA_MEM_ADVISE_UNSET_PREFERRED_LOCATION_HOST | cudaMemAdviseUnsetPreferredLocation | host
| CUDA_MEM_ADVISE_SET_ACCESSED_BY_HOST | cudaMemAdviseSetAccessedBy | host
| CUDA_MEM_ADVISE_UNSET_ACCESSED_BY_HOST | cudaMemAdviseUnsetAccessedBy | host
|====

==== Supported image formats

Supported image formats are:

* r8g8b8a8_unorm
* r16g16b16a16_unorm
* r8g8b8a8_sint
* r16g16b16a16_sint
* r32b32g32a32_sint
* r8g8b8a8_uint
* r16g16b16a16_uint
* r32b32g32a32_uint
* r16b16g16a16_sfloat
* r32g32b32a32_sfloat
* b8g8r8a8_unorm

==== Samplers

In both SYCL and CUDA samplers consist of addressing mode, filtering mode and coordinate normalization mode. Mapping between SYCL and CUDA values is defined in tables <<table.cuda.memmodel.sampler_addressing>>, <<table.cuda.memmodel.sampler_filtering>> and <<table.cuda.memmodel.sampler_normalization>>. In CUDA addressing modes for all dimesnions will be the same, as CUDA allows different addressing modes for different dimesnions, while SYCL does not. 

[[table.cuda.memmodel.sampler_addressing]]
.Mapping of SYCL sampler addressing modes to CUDA
[width="100%",options="header",cols="50%,50%"]
|====
| SYCL sampler addressing mode | CUDA sampler addressing mode
| [code]#sycl::addressing_mode::mirrored_repeat# | [code]#cudaAddressModeMirror#
| [code]#sycl::addressing_mode::repeat# | [code]#cudaAddressModeWrap#
| [code]#sycl::addressing_mode::clamp_to_edge# | [code]#cudaAddressModeClamp#
| [code]#sycl::addressing_mode::clamp# | [code]#cudaAddressModeClamp#
| [code]#sycl::addressing_mode::none# | [code]#cudaAddressModeBorder#
|====

SYCL allows [code]#sycl::addressing_mode::mirrored_repeat# and [code]#sycl::addressing_mode::repeat# to be used together with unnormalized coordinates. In this case the resulting coordinates are undefined. CUDA does not allow this, so if [code]#sycl::addressing_mode::mirrored_repeat# or [code]#sycl::addressing_mode::repeat# is specified together with unnormalized coordinates, [code]#cudaAddressModeBorder# is used instead.

[[table.cuda.memmodel.sampler_filtering]]
.Mapping of SYCL sampler filtering modes to CUDA
[width="100%",options="header",cols="50%,50%"]
|====
| SYCL sampler filtering mode | CUDA sampler filtering mode
| [code]#sycl::filtering_mode::nearest# | [code]#cudaFilterModePoint#
| [code]#sycl::filtering_mode::linear# | [code]#cudaFilterModeLinear#
|====

[[table.cuda.memmodel.sampler_normalization]]
.Mapping of SYCL sampler coordinate normalization modes to CUDA
[width="100%",options="header",cols="50%,50%"]
|====
| SYCL sampler coordinate normalization mode | CUDA sampler coordinate normalization mode
| [code]#sycl::coordinate_normalization_mode::normalized# | [code]#normalizedCoords = true#
| [code]#sycl::coordinate_normalization_mode::unnormalized# | [code]#normalizedCoords = false#
|====

==== Address Spaces

Table <<table.cuda.memmodel.address_spaces>> maps SYCL address spaces to CUDA address spaces.

[[table.cuda.memmodel.address_spaces]]
.Mapping from SYCL address spaces to CUDA address spaces
[width="100%",options="header",cols="50%,50%"]
|====
| SYCL Address Space | CUDA Address Space
| Global memory | global
| Local memory | shared
| Private memory | registers or local
| Generic memory | generic
| Constant memory | const
|====

==== Atomics

Not all CUDA devices support all memory orders. If a particular memory order is unsupported by a CUDA device, it can be unsupported in the SYCL CUDA backend for that device. Sequentially consistent atomics are currently not supported on any device, so the SYCL CUDA backend is not required to implement them. The mappings of other memory orders (when supported by the device) is defined in table <<table.cuda.memmodel.memory_orders>>.

[[table.cuda.memmodel.memory_orders]]
.Mapping from [code]#sycl::memory_order# to PTX ISA memory orders
[width="100%",options="header",cols="50%,50%"]
|====
| [code]#sycl::memory_order# | PTX ISA Memory Order
| [code]#memory_order::relaxed# | relaxed
| [code]#memory_order::acquire# | acquire
| [code]#memory_order::release# | release
| [code]#memory_order::acq_rel# | acq_rel
| [code]#memory_order::seq_cst# | undefined
|====

Mapping of memory scopes (when supported by the device) is defined in table [table.cuda.memmodel.memory_scopes]. [code]#memory_scope::work_item# does not require any consistency between different work items, so it can be mapped to non-atomic operation.

[[table.cuda.memmodel.memory_scopes]]
.Mapping from [code]#sycl::memory_scope# to PTX ISA memory scopes
[width="100%",options="header",cols="50%,50%"]
|====
| [code]#sycl::memory_scope# | PTX ISA Memory Scope
| [code]#memory_scope::work_item# | 
| [code]#memory_scope::sub_group# | cta
| [code]#memory_scope::work_group# | cta
| [code]#memory_scope::device# | gpu
| [code]#memory_scope::system# | system
|====

==== Fences

If a device supports the [code]#fence# PTX instruction the mapping of memory orders is defined in <<table.cuda.memmodel.fence_memory_orders>>. Otherwise all memory orders (except relaxed) are mapped to the [code]#membar# instruction.

[[table.cuda.memmodel.fence_memory_orders]]
.Mapping from [code]#sycl::memory_order# to PTX ISA memory orders when used in fences
[width="100%",options="header",cols="50%,50%"]
|====
| [code]#sycl::memory_order# | PTX ISA Memory Order
| [code]#memory_order::relaxed# | none
| [code]#memory_order::acquire# | acq_rel
| [code]#memory_order::release# | acq_rel
| [code]#memory_order::acq_rel# | acq_rel
| [code]#memory_order::seq_cst# | sc
|====

If future versions of PTX ISA define fence instructions with only acquire or only release memory order, these can be used as well for [code]#memory_order::acquire# and [code]#memory_order::release# on devices that support them.

Mapping of SYCL memory scopes to PTX ISA is the same as for atomics. It is defined in <<table.cuda.memmodel.memory_scopes>>.

[[sub:cuda:execution_model]]
=== Execution Model

CUDA's execution model is similar to SYCL's. CUDA uses kernels to
offload computation, splitting the host and GPU into asynchronous 
computing devices. In general, except for CUDA's dynamic 
parallelism extensions, kernels are called by the host. 

CUDA GPUs are constructed out of streaming multiprocessors (SM) 
which perform the actual computation. Each SM consists of 8 scalar 
cores, shared memory, registers, a load/store unit, and a scheduler 
unit. CUDA uses a hierarchy of threads to organize the execution of
kernels. Kernels are split up into thread blocks. The threadblocks 
form a grid each thread can identify its location within the grid 
using a block ID. The grid is a concept used to index threadblocks 
the grid can be one, two, or three dimensions. Each thread block is 
tied to a single SM. Similar to a thread block's location within the 
grid, each thread's position within the block can be identified with 
a one, two, or three dimensional thread ID. 

Pre-Volta GPU architectures breaks thread blocks into warps which 
consist of 32 threads. The warp is processed by the SM concurrently. 
For one warp instruction to be executed requires 4 SM clock cycles. 
SM's execute multiple warp instructions. The warps instructions are 
prioritized and scheduled to minimize overhead. 

Volta and more recent GPU architectures use independent thread 
scheduling. In addition, each thread can access memory within a 
unified virtual address space. Threads must synchronize with other 
threads using execution barriers, synchronization primitives and 
Cooperative Groups to utilize unified memory.

In SYCL, group functions and synchronizations are convergent, meaning 
all work-items must reach them by the same control flow. Work-items 
encountering a group function or synchronization point under diverse 
conditions results in undefined behaviour. Therefore, any device specific 
capability of independent forward progress among work-items is not exposed 
in SYCL, and will not be observable to users. Independent forward progress
of work-items may be achieved through the CUDA interop API, which gives
the same guarantees as native CUDA.

SYCL has a similar execution hierarchy consisting of kernels. 
The kernel is broken down into work-items. Each work-item concurrently
executes an instance of the kernel on a piece of memory. Work-items 
can be combined into work-groups that have designated shared memory.
Work-groups can synchronize their work-items with work-group barriers.

There are some equivalences between CUDA and SYCL execution models. 
For example, CUDA's stream multiprocessor is equal to a SYCL compute 
unit. CUDA's grid is similar to SYCL's nd_range as it is the highest 
level grouping of threads, not including the whole kernel. Both 
nd_range and grid can segment the groups of threads into one, two, or 
three dimensions. SYCL sub-groups roughly map to
cooperative groups `thread_block_tile` as it allows for the
work-group/thread block to be further subdivided into concurrent threads.
Likewise, thread blocks map directly to work-groups, and a
single thread is a SYCL work-item.

CUDA primarily synchronizes the threads through two functions,
`cudaStreamSynchronize()` and `__syncthreads()`. 
`cudaStreamSynchronize()` blocks work from being performed until all 
threads on the device has been completed. `__syncthreads()` waits for 
all threads within a thread block to reach the same point. So 
`cudaStreamSynchronize()` is similar to queue.wait(), buffer 
destruction, and other host-device synchronization events within SYCL. 
`__syncthreads()` synchronizes the threads within a thread block which
is analogous to the work-group barrier.

CUDA's warp concept has no SYCL equivalent. If a user were to write 
warp aware code it would be non-generic SYCL code and specific to the 
CUDA backend.

CUDA allows for more detailed thread and memory management through 
Cooperative Groups. Cooperative Groups allow for synchronizing at the 
grid level and organizing subgroups in sizes smaller than a warp. 
Cooperative Groups do not have an equivalent within SYCL 2020 and are 
not yet supported.

==== Work Item Mapping

A SYCL `nd_range` will tranpose indices as it maps to hardware memory.
This gives better memory access patterns, in general.

SYCL uses row major memory ordering, meaning in some memory object the 
rows will be contiguous in memory. SYCL follows C++ convention in 
this regard. Following the row-major paradigm, it is intuitive to imagine 
each work-item in a `parallel_for` indexing through a contiguous block of 
memory as it does its work. However, this gives poorly coalesced memory 
accesses, as a given contiguous chunk of data being loaded may only pass 
memory to a single work-item. More efficient memory access patterns are 
achieved when each load of contiguous data can give data to as many 
work-items as possible. Meaning the data used by a given work-item
is non-contiguous.

SYCL makes this intuitive row-major C++ approach give good memory access 
patterns by flipping the indices of the `nd_range`, as it maps to hardware.

The linear id (whose use is not recommended) of a two dimensional `nd_range` 
can be calculated using:

[source,c++]
----
cgh.parallel_for(range<2>(64, 128), [=](item<2> it) {
  size_t linearIdx = it.get_id(1) + (it.get_id(0) * it.get_range(0));
  ...
});
----

Notice that rows appear to be accessed in a column-major, rather than 
row-major, format. This is only the case because the indices are flipped 
by the SYCL implementation. All memory in SYCL is stored in row-major format.

It is best to avoid calculating the linear index manually; it is better
to use a multi-dimensional `sycl::id` to index into memory, as it doesn't
expose index-flipping to the user.

[[table.cuda.CUDA_features_to_SYCL]]
.CUDA execution features with their corresponding SYCL features
[width="100%",options="header",cols="50%,50%"]
|====
| [code]#SYCL#                                                       | [code]#CUDA#
| [code]#Compute unit#                                               | [code]#Streaming multiprocessor#
| [code]#nd_range#                                                   | [code]#grid#
| [code]#work-group#                                                 | [code]#Thread block#
| [code]#sub-group#                                                  | [code]#thread_block_tile#
| [code]#work-item#                                                  | [code]#Thread#
| [code]#SYCL nd_item synchronization#                               | [code]#cudaStreamSynchronize#
| [code]#work-group barrier#                                         | [code]#__syncthread#
|====

[[sec::programming_interface]]
== Programming Interface

[[sub:cuda:application_interoperability]]
=== Application Interoperability

This section describes the API level interoperability between SYCL and CUDA.

The CUDA backend supports API interoperability for `platform`, `device`,
`context`, `queue`, `event` and `buffer`. Interoperability for `kernel`,
`kernel_bundle`, `device_image`, `sampled_image` and `unsampled_image` is not
supported.

[[table.cuda.appinterop.nativeobjects]]
.Types of native backend objects application interoperability
[width="100%",options="header",cols="20%,20%,20%,40%"]
|====
| [code]#SyclType# | [code]#backend_input_t<backend::cuda, SyclType># | [code]#backend_return_t<backend::cuda, SyclType># | Description
| [code]#platform# | `std::vector<CUdevice>`   | `std::vector<CUdevice>`  | A SYCL platform encapsulates a list of CUDA devices.
| [code]#device#   | `CUdevice`                | `CUdevice`               | A SYCL device encapsulates a CUDA device.
| [code]#context#  | `CUcontext`               | `std::vector<CUcontext>` | A SYCL context can encapsulate multiple CUDA contexts , however it is not possible to create a SYCL context from multiple CUDA contexts.
| [code]#queue#    | `CUstream`   | `CUstream` | A SYCL queue encapsulates a CUDA stream.
| [code]#event#    | `CUevent`    | `CUevent`  | A SYCL event encapsulates a CUDA event.
| [code]#buffer# | `struct { CUdeviceptr ptr; size_t size; }` | `CUdeviceptr` | A SYCL buffer encapsulates a CUDA device pointer.
|====

[[table.cuda.appinterop.make_interop_APIs]]
.[code]#make_*# Interoperability APIs for native backend objects.
[width="100%",options="header",cols="40%,60%"]
|====
| CUDA interoperability function                                    |  Description
| [code]#template<backend Backend> +
platform + 
make_platform(const backend_input_t<Backend, platform> &backendObject);# 
        | Create a SYCL `platform` from a list of CUDA device, the list must contain at least one CUDA device. As the SYCL execution environment for the CUDA backend contains a fixed number of platforms that are enumerated via `sycl::platform::get_platforms()`. Calling this function does not create a new platform. Rather it merely creates a `sycl::platform` object that is a copy of one of the platforms from that enumeration.

| [code]#template<backend Backend> +
device +
make_device(const backend_input_t<Backend, device> &backendObject);# 
        | Construct a SYCL `device` from a CUDA device. As the SYCL execution environment for the CUDA backend contains a fixed number of devices that are enumerated via `sycl::device::get_devices()`. Calling this function does not create a new device. Rather it merely creates a `sycl::device` object that is a copy of one of the devices from that enumeration.

| [code]#template<backend Backend> +
context +
make_context(const backend_input_t<Backend, context> &backendObject,
                     const async_handler asyncHandler = {});# 
        | Create a SYCL `context` from a CUDA context.

| [code]#template<backend Backend> +
queue +
make_queue(const backend_input_t<Backend, queue> &backendObject,
                 const context &targetContext,
                 const async_handler asyncHandler = {});# 
        | Create a SYCL `queue` from a CUDA stream. The provided `targetContext` must encapsulate the same CUDA context as the provided CUDA stream.

| [code]#template<backend Backend> +
event +
make_event(const backend_input_t<Backend, event> &backendObject,
                 const context &targetContext);# 
        | Create a SYCL `event` from a CUDA event.

| [code]#template <backend Backend, typename T, int dimensions = 1,
          typename AllocatorT = buffer_allocator<std::remove_const_t<T>>> +
buffer<T, dimensions, AllocatorT> +
make_buffer(const backend_input_t<Backend, buffer<T, dimensions, AllocatorT>>
               &backendObject,
           const context &targetContext, event availableEvent);#
        | Create a SYCL `buffer` from a CUDA device pointer.` The CUDA pointer must be within the provided `targetContext`. The `availableEvent` parameter can be used for synchronization and indicates when the CUDA pointer is ready to be used. Only `dimensions == 1` is supported.
 
| [code]#template <backend Backend, typename T, int dimensions = 1,
           typename AllocatorT = buffer_allocator<std::remove_const_t<T>>> +
buffer<T, dimensions, AllocatorT> +
make_buffer(const backend_input_t<Backend, buffer<T, dimensions, AllocatorT>>
                &backendObject,
            const context &targetContext);#
        | Create a SYCL `buffer` from a CUDA device pointer.` The CUDA pointer must be within the provided `targetContext`. Only `dimensions == 1` is supported.

|====

==== Ownership of native backend objects

The CUDA backend retains ownership of all native CUDA objects obtained through
the interoperability API, therefore associated SYCL objects must be kept alive
for the duration of the CUDA work using these native CUDA objects.

When creating a SYCL object from a native CUDA object SYCL does not take
ownership of the object and it is up to the application to dispose of them when
appropriate.

[[sub:cuda:kernel_function_interoperability]]
=== Kernel Function Interoperability

This section describes the kernel function interoperability for the CUDA
backend.

The CUDA backend supports kernel function interoperability for the `accessor`,
`local_accessor`, `sampled_image_accessor`, `unsampled_image_accessor` and
`stream` classes.

The CUDA backend does not support interoperability for the `device_event` class
as there's no equivalent in CUDA.

Address spaces in CUDA are associated with variable decorations rather than the
type, so when pointers are passed as parameters to a function the parameter
types does not need to be decorated with an address space, instead it's simply a
raw un-decorated pointer. For this reason the `accessor`,  `local_accessor` and
`stream` classes map to a raw undecorated pointer which can be implemented using
the generic address space.

Other kernel function types in CUDA are represented by aliases provided in the
`sycl::cuda` namespace. These are provided for the `sampled_image_accessor`,
and `unsampled_image_accessor` classes; `sycl::cuda::texture` and
`sycl::cuda::surface` respectively.

Below is a table of the `backend_input_t` and `backend_return_t` specializations
for the SYCL classes which support kernel function interoperability.

[[table.cuda.kernelinterop.nativeobjects]]
.Types of native backend objects kernel function interoperability
[width="100%",options="header",cols="20%,20%,20%,40%"]
|====
| [code]#SyclType#                                                   | [code]#backend_input_t<backend::cuda, SyclType># | [code]#backend_return_t<backend::cuda, SyclType># | Description
| [code]#accessor<T, Dims, Mode, target::device>#                    | T * | T * | Convert a SYCL `accessor` to an undecorated raw pointer.
| [code]#accessor<T, Dims, Mode, target::constant_buffer>#           | T * | T * | Convert a SYCL `accessor` to an undecorated raw pointer.
| [code]#accessor<T, Dims, Mode, target::local>#                     | T * | T * | Convert a SYCL `accessor` to an undecorated raw pointer.
| [code]#local_accessor<T, Dims>#                                    | T * | T * | Convert a SYCL `accessor` to an undecorated raw pointer.
| [code]#sampled_image_accessor<T, 1, Mode, image_target::device>#   | sycl::cuda::texture<T, 1> | sycl::cuda::texture<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::texture` interoperability type with the same type and dimensions.
| [code]#sampled_image_accessor<T, 2, Mode, image_target::device>#   | sycl::cuda::texture<T, 2> | sycl::cuda::texture<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::texture` interoperability type with the same type and dimensions.
| [code]#sampled_image_accessor<T, 3, Mode, image_target::device>#   | sycl::cuda::texture<T, 3> | sycl::cuda::texture<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::texture` interoperability type with the same type and dimensions.
| [code]#unsampled_image_accessor<T, 1, Mode, image_target::device># | sycl::cuda::surface<T, 1> | sycl::cuda::surface<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::surface` interoperability type with the same type and dimensions.
| [code]#unsampled_image_accessor<T, 2, Mode, image_target::device># | sycl::cuda::surface<T, 2> | sycl::cuda::surface<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::surface` interoperability type with the same type and dimensions.
| [code]#unsampled_image_accessor<T, 3, Mode, image_target::device># | sycl::cuda::surface<T, 3> | sycl::cuda::surface<T, 1> | Convert a SYCL `accessor` to the `sycl::cuda::surface` interoperability type with the same type and dimensions.
| [code]#stream#                                                     | signed char * | signed char * | Convert a SYCL `accessor` to an undecorated raw signed char pointer.
|====


[[sec:non_core_features_and_extensions]]
== Non-core features and extensions

Additional CUDA features are available depending upon the devices compute capability.
SYCL can support these optional CUDA features with extensions.
Unlike OpenCL, CUDA needs to know if the extension is available at compile time. 
As a result there are no valid CUDA extensions which can be passed to `has_extension`.

As the extension must be known at runtime CUDA extensions are best implemented 
using feature test macros. The test macro format is 
SYCL_EXT_<vendorstring>_<featurename>. For CUDA extensions this format translates 
to SYCL_EXT_NVIDIA_<featurename>. Similarly, the format for the naming of extension 
classes and enumerations should be ext_<vendorstring>_<featurename>. Which in this context
becomes ext_NVIDIA_<featurename>. Given the necessity to know the extension at 
compile-time, the usage of extension macros should be the primary method of determining 
if the extension is available in the SYCL implementation not. 
A list of non-core CUDA features which have SYCL support is below.
Non-core CUDA features for require a compute capability of greater than 5.

TODO: The table below shows a proposal for SYCL supported CUDA extensions.
The table should be developed with other members of the SYCL community.

[[table.extensionsupport]]
.SYCL support for CUDA 11.3 extensions
[width="100%",options="header",cols="35%,35%,15%, 15"]
|====
| SYCL Aspect              | CUDA Extension                                        | Core SYCL API | Required Compute Capability 
| [code]#aspect::fp16#     | [code]#16-bit floating point#                         | Yes           | 5.3 or greater
| -                        | [code]#Tensor Cores#                                  | No            | 7 or greater
| -                        | [code]#Atomic floating-point operations#              | No            | 6 or greater
|====

=== Aspects
Aspects are used to query what features and attributes a device has. Some aspects such as `fp16`
are non-core CUDA features. Therefore, the runtime must be able to determine what aspects CUDA 
devices have. This can be performed by querying `cudaDeviceProp::major` and `cudaDeviceProp::minor`
to find out the compute capability. The compute capability indicates what extensions are
available to the device, and therefore what aspects are available.

[[sec:cuda:extension-fp16]]
=== Half precision floating-point

The half scalar data type: [code]#half# and the half vector data types:
[code]#half1#, [code]#half2#, [code]#half3#,
[code]#half4#, [code]#half8# and [code]#half16# must be
available at compile-time. However a kernel using these types is only
supported on devices that have [code]#aspect::fp16#, i.e. compute capability
5.3 or greater.

[[sub:cuda:extensions]]
=== Extensions

[[sub:cuda:builtin-kernel-functions]]
=== Built-in Kernel Functions
The CUDA backend specification currently does not define any built-in kernel 
functions.


[[sub:cuda:error_handling]]
=== Error Handling

SYCL uses `sycl::errc` as an enum class to hold error codes. These error
codes may originate in the SYCL runtime or be passed from other runtimes to
the SYCL runtime. When a `sycl::exception` is thrown, the `sycl::errc` can
be queried using the exception's `.code()` method. Possible values for 
`sycl::errc` include: `success`, `runtime`, `memory_allocation`, and more.

If there is a CUDA driver API error associated with an exception triggered, then the
CUDA error code can be obtained by the free function `CUresult sycl::cuda::get_error_code(sycl::exception&)`. In the case where there is
no CUDA error associated with the exception triggered, the CUDA error
code will be `CUDA_SUCCESS`.

Most of the SYCL error codes that form sycl::errc are specifically defined as errors thrown during calls to the SYCL API or SYCL runtime. There are also some cases of sycl::errc which cover errors thrown during the compilation or execution of device code.
It is suitable to map CUDA errors to such cases, such that an exception, "cuda_exception", that was created due to a CUDA error, may, upon execution of `cuda_exception.code()`, return a `std::error_code` relating to the `sycl::errc` case that the CUDA error maps to; whilst `sycl::cuda::get_error_code(cuda_exception)` will return the original CUDA error code.

The relevant `sycl::errc` cases and the CUDA errors that they may be mapped from are listed below.

==== build

`sycl::errc::build` is defined as:

_Error from an online compile or
link operation when compiling,
linking, or building a kernel bundle for a device._

which may be mapped from `CUDA_ERROR_NO_BINARY_FOR_GPU`, `CUDA_ERROR_JIT_COMPILER_NOT_FOUND`, `CUDA_ERROR_INVALID_PTX`, `CUDA_ERROR_UNSUPPORTED_PTX_VERSION`, `CUDA_ERROR_SHARED_OBJECT_INIT_FAILED`, `CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND`.


==== memory_allocation

`sycl::errc::memory_allocation` is defined as:

_Error on memory allocation on the
SYCL device for a SYCL kernel._

which may be mapped from `CUDA_ERROR_OUT_OF_MEMORY`.

==== kernel_argument

`sycl::errc::kernel_argument` is defined as:

_The application has passed an invalid argument to a SYCL kernel
function. This includes captured
variables if the SYCL kernel function is a lambda function._

which may be mapped from `CUDA_ERROR_NOT_FOUND`.

[[sub:cuda:non_core_properties]]
=== Non-Core Properties

The constructors for most SYCL library objects, such as for `sycl::queue` or 
`sycl::context`, accept the parameter `sycl::property_list`, which can affect 
the semantics of the compilation or linking operation.

There are currently no CUDA backend specific properties, meaning any properties
relating to the CUDA backend will be defined by a given implementation.

[[sub:cuda:graphics_apis_interop]]
=== Interoperability with Graphics APIs

Interoperability between SYCL and OpenGL or DirectX is not directly provided 
by the SYCL interface. However, since the CUDA API provides interoperability 
with these APIs, interoperability between SYCL and OpenGL or DirectX is best 
done indirectly through interoperability with the CUDA API.

// %%%%%%%%%%%%%%%%%%%%%%%%%%%% end cuda_backend %%%%%%%%%%%%%%%%%%%%%%%%%%%%
